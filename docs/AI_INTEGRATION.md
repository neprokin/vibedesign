# AI-интеграция: Архитектура и рабочие процессы

## Обзор

AI-интеграция объединяет Figma, MCP-сервер и Cursor в единую экосистему для автоматизации дизайн-процессов с помощью искусственного интеллекта. Эта документация описывает архитектуру системы, ключевые компоненты, рабочие процессы и технические детали реализации.

## Компоненты системы

### 1. Точки взаимодействия с AI

#### 1.1. Плагин Figma
- **Панель плагина**: Основной интерфейс для взаимодействия с AI в Figma
- **Чат-интерфейс**: Текстовые запросы и беседа с AI
- **Панель инструментов**: Кнопки для анализа, генерации и оптимизации дизайна
- **Контекстное меню**: Опции AI при выделении элементов

#### 1.2. Cursor IDE
- **Cursor AI Chat**: Интеграция с чатом Cursor для запросов о дизайне
- **Cursor Notepads**: Заметки с поддержкой AI для планирования дизайна
- **Cursor Agent**: Проактивные подсказки при работе с дизайн-кодом

### 2. Серверные компоненты

#### 2.1. MCP-сервер
- **Координация запросов**: Маршрутизация между Figma, Cursor и AI-моделями
- **Управление контекстом**: Поддержание состояния сессии и контекста диалога
- **Инструменты AI**: Логика для различных задач анализа и генерации

#### 2.2. AI-модуль
- **LLM-адаптеры**: Коннекторы к различным AI-моделям (OpenAI, Anthropic)
- **Промпт-инжиниринг**: Система шаблонов и конструкторов запросов
- **Кэширование результатов**: Оптимизация частых запросов

## Коммуникационные потоки

### 1. Figma → MCP → AI

```
┌───────────┐     ┌───────────┐     ┌───────────┐     ┌───────────┐
│  Плагин   │ --> │ WebSocket │ --> │ MCP-сервер│ --> │ AI-модель │
│  Figma    │     │  сервер   │     │           │     │           │
└───────────┘     └───────────┘     └───────────┘     └───────────┘
                                          |
                                          v
                                     ┌───────────┐
                                     │  Дизайн-  │
                                     │  токены   │
                                     └───────────┘
```

### 2. Cursor → MCP → AI → Figma

```
┌───────────┐     ┌───────────┐     ┌───────────┐     ┌───────────┐
│  Cursor   │ --> │ MCP Proto-│ --> │ AI-модель │ --> │ WebSocket │
│  IDE      │     │  col      │     │           │     │  сервер   │
└───────────┘     └───────────┘     └───────────┘     └───────────┘
                        |                                   |
                        v                                   v
                   ┌───────────┐                      ┌───────────┐
                   │ MCP-сервер│                      │  Плагин   │
                   │           │                      │  Figma    │
                   └───────────┘                      └───────────┘
```

## Рабочие процессы

### 1. Анализ дизайна

**Инициация**: Пользователь выбирает элементы в Figma и нажимает "Анализировать"

**Поток данных**:
1. Плагин Figma собирает информацию о выбранных элементах
2. Данные отправляются через WebSocket в MCP-сервер
3. MCP-сервер формирует структурированный запрос для AI, включая:
   - Структуру элементов
   - Визуальные свойства
   - Дизайн-токены проекта
   - Цели анализа (заданные пользователем)
4. AI анализирует данные и генерирует отчет
5. MCP-сервер обрабатывает результат и отправляет в плагин
6. Плагин отображает интерактивный отчет с возможностью применения рекомендаций

**Пример запроса к AI**:
```
Проанализируй следующий UI-компонент: [структурированное описание компонента в JSON]

Оцени следующие аспекты:
1. Соответствие дизайн-системе: [дизайн-токены проекта]
2. Контрастность и доступность
3. Визуальная иерархия
4. Консистентность с другими элементами

Формат ответа: структурированный JSON со следующими разделами:
- общая оценка (1-10)
- сильные стороны
- проблемы
- рекомендации
```

### 2. Генерация компонентов

**Инициация**: Пользователь описывает нужный компонент в плагине Figma или Cursor

**Поток данных**:
1. Запрос обрабатывается в MCP-сервере
2. Система анализирует дизайн-токены и существующие компоненты
3. AI генерирует спецификацию компонента в JSON-формате
4. MCP-сервер конвертирует спецификацию в инструкции для плагина
5. Плагин создает компонент в Figma
6. ID созданного компонента возвращается в исходную точку запроса

**Пример запроса к AI**:
```
Создай спецификацию для компонента: [описание компонента]

Используй следующие дизайн-токены:
- цвета: [список токенов цвета]
- типографика: [токены шрифтов]
- размеры: [токены размеров]

Учти следующие требования:
- компонент должен соответствовать существующей дизайн-системе
- должен быть адаптивным
- должен иметь корректную семантическую структуру

Формат ответа: JSON-спецификация в формате Figma API
```

### 3. Генерация кода по дизайну

**Инициация**: Пользователь выбирает элемент в Figma и запрашивает код

**Поток данных**:
1. Плагин собирает детальную информацию о компоненте
2. MCP-сервер обрабатывает данные и формирует запрос к AI
3. AI генерирует код (React/Vue/HTML/CSS)
4. Результат отправляется в Cursor или отображается в плагине
5. Пользователь может применить или отредактировать код

**Пример запроса к AI**:
```
Сгенерируй React-компонент для следующего элемента дизайна:
[структурированное описание компонента]

Требования к коду:
- использовать [фреймворк: React/Vue/Angular]
- стилизация через [CSS/Tailwind/Styled Components]
- должен быть адаптивным
- должен соответствовать доступности WCAG AA

Формат ответа: полный код компонента с комментариями
```

### 4. Мультимодальное взаимодействие

**Инициация**: Пользователь задает вопрос или запрашивает действие в чате

**Поток данных**:
1. Запрос обрабатывается MCP-сервером
2. Система определяет тип запроса и необходимый контекст
3. При необходимости запрашиваются дополнительные данные из Figma
4. AI генерирует ответ или действие
5. Результат отображается в интерфейсе и/или выполняется в Figma

**Примеры запросов**:
- "Какие цвета используются в этом макете и соответствуют ли они нашей дизайн-системе?"
- "Создай версию этого компонента для мобильной версии"
- "Объясни логику организации слоев в этом компоненте"

## Технические детали реализации

### 1. LLM-адаптер

**Назначение**: Унифицированный интерфейс для взаимодействия с различными AI-моделями

**Ключевые функции**:
- Абстракция над API различных моделей (OpenAI, Anthropic)
- Управление промптами и контекстом
- Обработка и форматирование ответов
- Оптимизация токенов и кэширование

**Интерфейс**:
```typescript
interface LLMRequest {
  prompt: string;
  temperature?: number;
  maxTokens?: number;
  stopSequences?: string[];
  systemMessage?: string;
  context?: Record<string, any>;
}

interface LLMResponse {
  content: string;
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
  meta?: Record<string, any>;
}

interface LLMAdapter {
  sendPrompt(request: LLMRequest): Promise<LLMResponse>;
  streamPrompt(request: LLMRequest, callback: (chunk: string) => void): Promise<LLMResponse>;
}
```

### 2. Промпт-инжиниринг

**Назначение**: Создание эффективных запросов к AI для получения качественных результатов

**Ключевые компоненты**:
- Шаблоны промптов для разных задач
- Система для создания промптов из модулей
- Механизмы инъекции контекста

**Пример структуры шаблона промпта**:
```typescript
interface PromptTemplate {
  id: string;
  description: string;
  template: string;
  variables: string[];
  systemMessage?: string;
  defaultParams?: Record<string, any>;
}

const analyzeLayoutPrompt: PromptTemplate = {
  id: 'analyze_layout',
  description: 'Анализ компоновки элементов интерфейса',
  template: `Проанализируй следующий макет UI:
{{layout_description}}

Оцени следующие аспекты:
1. Визуальная иерархия
2. Группировка и выравнивание
3. Использование пространства
4. Адаптивность

{{additional_criteria}}

Формат ответа:
{{output_format}}`,
  variables: ['layout_description', 'additional_criteria', 'output_format'],
  systemMessage: 'Ты эксперт по UI/UX дизайну, специализирующийся на анализе макетов.',
};
```

### 3. Инструменты AI

Основные инструменты, которые будут реализованы:

#### 3.1. Инструменты анализа
- **analyze_layout**: Анализ компоновки и структуры интерфейса
- **analyze_styles**: Проверка стилей и соответствия дизайн-системе
- **analyze_accessibility**: Оценка доступности интерфейса
- **generate_suggestions**: Предложения по улучшению дизайна

#### 3.2. Инструменты генерации
- **generate_component**: Создание компонентов по текстовому описанию
- **generate_variants**: Создание вариаций компонентов
- **generate_responsive**: Генерация адаптивных версий компонентов
- **generate_code**: Генерация кода для реализации компонентов

#### 3.3. Инструменты для работы с текстом
- **optimize_copy**: Улучшение текстового содержимого
- **localize_text**: Помощь в локализации интерфейса
- **check_terminology**: Проверка соответствия терминологии

## Настройка и конфигурация

### 1. Конфигурация AI-моделей

```
AI_MODEL=gpt-4
AI_TEMPERATURE=0.7
AI_MAX_TOKENS=4096
AI_TIMEOUT=60000

# OpenAI
OPENAI_API_KEY=your_api_key
OPENAI_ORGANIZATION=your_org_id

# Anthropic (опционально)
ANTHROPIC_API_KEY=your_api_key
```

### 2. Конфигурация промптов

```
# Пути к шаблонам промптов
PROMPTS_DIR=./prompts

# Настройки промптов по умолчанию
DEFAULT_SYSTEM_MESSAGE="Ты AI-ассистент, помогающий с дизайном интерфейсов."
DEFAULT_OUTPUT_FORMAT=json
```

### 3. Настройки кэширования

```
# Кэширование LLM-запросов
LLM_CACHE_ENABLED=true
LLM_CACHE_TTL=3600 # 1 час
LLM_CACHE_SIZE=100 # максимальное количество записей
```

## Расширение функциональности

### 1. Добавление новых инструментов

Для добавления нового AI-инструмента необходимо:

1. Создать файл инструмента в `src/tools/ai/` (например, `analyze_colors.ts`)
2. Реализовать обработчик инструмента
3. Создать шаблон промпта в `prompts/` (например, `analyze_colors.prompt.json`)
4. Зарегистрировать инструмент в MCP-сервере

**Пример структуры нового инструмента**:
```typescript
import { MCPRequest } from '@modelcontextprotocol/sdk';
import { z } from 'zod';
import { ToolResult } from '../../types';
import { LLMAdapter } from '../../services/llm-adapter';
import { PromptManager } from '../../services/prompt-manager';
import { logger } from '../../utils/logger';

// Параметры инструмента
export interface AnalyzeColorsParams {
  fileKey: string;
  nodeId?: string;
  includeChildNodes?: boolean;
}

// Схема валидации
export const analyzeColorsSchema = z.object({
  fileKey: z.string().min(1),
  nodeId: z.string().optional(),
  includeChildNodes: z.boolean().optional(),
});

// Обработчик инструмента
export const analyzeColorsHandler = async (
  params: AnalyzeColorsParams,
  request: MCPRequest
): Promise<ToolResult<any>> => {
  // Реализация обработчика
};

// Описание инструмента
export const analyzeColorsDescription = {
  name: 'analyze_colors',
  description: 'Analyzes color usage in the design',
  parameterSchema: {
    /* ... */
  },
  handler: analyzeColorsHandler,
};
```

### 2. Интеграция с новыми LLM-моделями

Для добавления поддержки новой LLM-модели:

1. Создать новый адаптер в `src/services/llm/` (например, `gemini-adapter.ts`)
2. Реализовать интерфейс `LLMAdapter`
3. Добавить поддержку нового адаптера в фабрику `LLMAdapterFactory`
4. Обновить конфигурацию для поддержки новых параметров

## Заключение

AI-интеграция объединяет Figma, MCP-сервер и Cursor в мощную экосистему для автоматизации дизайн-процессов. Архитектура системы обеспечивает гибкость, расширяемость и высокую производительность, позволяя дизайнерам и разработчикам эффективно сотрудничать с помощью AI.

Система спроектирована с учетом модульности, что позволяет легко добавлять новые функции и адаптировать ее под конкретные нужды проекта. 