# AI-интеграция в MCP-сервер

## Обзор

Данный документ описывает архитектуру и особенности интеграции с AI-моделями (LLM) в MCP-сервере для автоматизации работы с Figma.

## Архитектура

AI-интеграция построена на следующих ключевых компонентах:

1. **Абстрактный интерфейс LLMAdapter** (`tools/llm_adapter.py`)
   - Определяет общий интерфейс для всех адаптеров LLM
   - Содержит методы для отправки промптов, генерации JSON, анализа дизайна и генерации вариантов

2. **Конкретная реализация адаптера** (`tools/openai_adapter.py`)
   - Реализует работу с OpenAI API (GPT-4, GPT-3.5)
   - Включает обработку ошибок и попытки повторного запроса при неудаче

3. **Фабрика адаптеров** (`tools/llm_factory.py`)
   - Создает нужный адаптер в зависимости от конфигурации
   - Позволяет легко добавлять новые реализации адаптеров

4. **Менеджер промптов** (`tools/prompt_manager.py`) 
   - Управляет шаблонами промптов с использованием Jinja2
   - Поддерживает метаданные, категории и параметризацию шаблонов

5. **Шаблоны промптов** (`resources/prompts/`)
   - Структурированные шаблоны с метаданными для разных задач
   - Разделены по категориям (design, general и т.д.)

6. **Инструменты MCP** в `server.py`
   - Инструменты для генерации вариантов компонентов
   - Инструменты для анализа дизайна
   - Инструменты для работы с шаблонами промптов
   - Инструмент для отправки произвольных промптов

## Конфигурация

Конфигурация AI-интеграции задается в файле `.env` или в конфигурационном файле. Основные параметры:

```ini
# LLM
LLM_ADAPTER_TYPE=openai
LLM_MODEL=gpt-4
OPENAI_API_KEY=your_api_key_here

# Общие настройки
TEMPLATES_DIR=path/to/templates
```

Также конфигурация поддерживается через класс `MCPServerOptions` в файле `types.py`.

## Использование в MCP-сервере

### Анализ дизайна

```python
@mcp.tool()
async def analyze_design(figma_data: dict, criteria: list = None):
    """Анализ дизайна и предложение улучшений с помощью LLM"""
    result = await llm_adapter.analyze_design(
        design_data=figma_data,
        criteria=criteria
    )
    return result
```

### Генерация вариантов компонента

```python
@mcp.tool()
async def generate_component(description: str, context: dict = None):
    """Генерация вариантов UI-компонента с помощью LLM"""
    variants = await llm_adapter.generate_variants(
        description=description, 
        context=context or {}, 
        num_variants=3
    )
    return variants
```

### Управление шаблонами промптов

```python
@mcp.tool()
async def list_prompt_templates(category: str = None):
    """Список доступных шаблонов промптов"""
    templates = prompt_manager.list_templates(category)
    return templates

@mcp.tool()
async def render_prompt_template(template_name: str, context: dict):
    """Рендеринг шаблона промпта с заданным контекстом"""
    result = prompt_manager.render_template(template_name, context)
    return result
```

## Добавление новых адаптеров

Для добавления нового адаптера LLM (например, для Anthropic Claude):

1. Создайте новый файл `tools/anthropic_adapter.py` с реализацией интерфейса `LLMAdapter`
2. Обновите `LLMFactory` для создания нового адаптера
3. Обновите `get_available_adapters()` для отображения нового адаптера в списке

## Добавление новых шаблонов

Для добавления нового шаблона промпта:

1. Создайте файл в `resources/prompts/` с расширением `.j2`
2. Добавьте блок метаданных в начале файла
3. Структурируйте шаблон с использованием синтаксиса Jinja2

## Расширение возможностей

Планируемые улучшения:

1. Интеграция с локальными моделями (Ollama, LM Studio)
2. Добавление кеширования результатов LLM-запросов
3. Инструменты для обучения модели на дизайн-системе
4. Многоходовые диалоги с LLM для уточнения дизайна

## Практические примеры использования

### Пример 1: Анализ существующего макета на соответствие принципам UX/UI

```python
# Получение данных из Figma
figma_data = await get_figma_data(node_id="12345:678")

# Настройка критериев анализа
criteria = [
    "Контраст и читаемость",
    "Согласованность с дизайн-системой",
    "Доступность для разных групп пользователей",
    "Отзывчивость макета для разных устройств"
]

# Анализ макета
analysis_result = await analyze_design(figma_data=figma_data, criteria=criteria)

# Отображение результата
print(json.dumps(analysis_result, indent=2, ensure_ascii=False))
```

### Пример 2: Генерация вариантов карточки продукта

```python
# Описание компонента
description = """
Карточка продукта для интернет-магазина со следующими элементами:
- Изображение продукта (соотношение сторон 4:3)
- Название продукта (1-2 строки)
- Цена и цена со скидкой (если применимо)
- Рейтинг (5-звездочная система)
- Кнопка "Добавить в корзину"
- Индикатор наличия товара
"""

# Контекст с информацией о дизайн-системе
context = {
    "design_system": {
        "colors": {
            "primary": "#3B82F6",
            "secondary": "#F59E0B",
            "text": "#1F2937",
            "background": "#FFFFFF"
        },
        "typography": {
            "heading": "Inter, 16px, bold",
            "body": "Inter, 14px, regular"
        },
        "spacing": {
            "xs": "4px",
            "sm": "8px",
            "md": "16px",
            "lg": "24px"
        }
    }
}

# Генерация вариантов
variants = await generate_component(
    description=description,
    context=context
)

# Отображение вариантов
for i, variant in enumerate(variants):
    print(f"Вариант {i+1}:\n{json.dumps(variant, indent=2, ensure_ascii=False)}\n")
```

## Оптимизация работы с LLM

### Структура промптов

Для получения наилучших результатов рекомендуется структурировать промпты следующим образом:

1. **Контекст** - краткое описание того, что мы пытаемся сделать
2. **Имеющиеся данные** - информация о дизайне, контексте и ограничениях
3. **Задача** - четкое описание того, что нужно сделать
4. **Формат ответа** - указание, в каком формате нужен ответ (JSON, HTML и т.д.)
5. **Критерии качества** - указание, какие аспекты особенно важны

### Пример структуры промпта для анализа доступности:

```jinja2
{# resources/prompts/analyze_accessibility.j2 #}
{% set meta %}
name: Analyze Accessibility
description: Анализирует дизайн на соответствие стандартам доступности (WCAG)
category: design
version: 1.0
{% endset %}

# Контекст
Вы - эксперт по доступности веб-интерфейсов, выполняющий аудит дизайна на соответствие стандартам WCAG 2.1.

# Имеющиеся данные
Дизайн для анализа:
```json
{{ design | tojson(indent=2) }}
```

# Задача
Проанализируйте предоставленный дизайн и определите:
1. Соответствие контраста текста стандартам WCAG AA (минимум 4.5:1 для обычного текста, 3:1 для большого текста)
2. Доступность интерактивных элементов (минимальный размер 44x44px)
3. Наличие альтернативного текста для изображений
4. Логичность порядка фокусировки
5. Правильность использования семантических ролей

{% if additional_criteria %}
Дополнительные критерии для анализа:
{% for criterion in additional_criteria %}
- {{ criterion }}
{% endfor %}
{% endif %}

# Формат ответа
Верните результат анализа в формате JSON:
```json
{
  "overall_score": 0-10,
  "issues": [
    {
      "element": "id элемента",
      "issue": "описание проблемы",
      "recommendation": "рекомендация по исправлению",
      "severity": "high|medium|low"
    }
  ],
  "recommendations": [
    "общая рекомендация 1",
    "общая рекомендация 2"
  ],
  "positive_aspects": [
    "положительный аспект 1",
    "положительный аспект 2"
  ]
}
```

# Критерии качества
- Будьте конкретны в своих рекомендациях
- Фокусируйтесь на стандартах WCAG 2.1 AA
- Приоритизируйте проблемы по их влиянию на пользователей с ограниченными возможностями
```

### Оптимизация токенов

Для экономии токенов и повышения эффективности:

1. **Передавайте только необходимые данные**
   - Фильтруйте данные Figma, передавая только те части, которые имеют отношение к задаче
   - Используйте инструмент `get_figma_data` с параметром `depth`, чтобы ограничить глубину получаемого дерева

2. **Используйте кеширование**
   - Кешируйте результаты запросов к Figma API
   - Кешируйте результаты часто используемых LLM-запросов

3. **Структура дизайн-данных**
   - Преобразуйте сложную структуру Figma в более компактный формат
   - Удаляйте ненужные поля (трансформации, эффекты и т.д.), если они не важны для задачи

## Работа с шаблонами промптов

### Структура шаблона промпта

```jinja2
{% set meta %}
name: Template Name
description: Template description
category: category_name
version: 1.0
{% endset %}

# Template content with {{ variables }}

{% if condition %}
Conditional content
{% endif %}

{% for item in items %}
- {{ item }}
{% endfor %}
```

### Метаданные шаблона

Метаданные шаблона могут включать:
- **name** - имя шаблона
- **description** - описание шаблона
- **category** - категория (design, code, general и т.д.)
- **version** - версия шаблона
- **models** - список поддерживаемых моделей
- **params** - ожидаемые параметры
- **response_format** - ожидаемый формат ответа

### Передача контекста в шаблон

```python
# Рендеринг шаблона с контекстом
prompt = prompt_manager.render_template(
    "analyze_accessibility.j2",
    {
        "design": figma_data,
        "additional_criteria": [
            "Совместимость с программами экранного доступа",
            "Адаптивность для пользователей с моторными нарушениями"
        ]
    }
)
```

## Советы по использованию LLM для дизайна

1. **Конкретность в запросах**
   - Вместо "Проанализируй этот дизайн" используйте "Проанализируй контраст и читаемость текста в этом дизайне"
   - Указывайте конкретные элементы, на которые нужно обратить внимание

2. **Итеративный подход**
   - Начинайте с общего анализа, затем переходите к конкретным аспектам
   - Используйте результаты предыдущих запросов для уточнения последующих

3. **Контекстуализация**
   - Указывайте целевую аудиторию, цели дизайна и ограничения
   - Добавляйте информацию о дизайн-системе и стилевых правилах

4. **Требование обоснования**
   - Просите модель объяснять свои рекомендации
   - Запрашивайте конкретные примеры из лучших практик

5. **Баланс между детализацией и обобщением**
   - Для начальных этапов дизайна лучше использовать более общие запросы
   - Для доработки существующего дизайна - более детализированные запросы

## Мониторинг и отладка

### Логирование запросов

```python
# Включение логирования запросов в LLMAdapter
llm_adapter.enable_logging("logs/llm_requests.log")

# Запрос с логированием
result = await llm_adapter.send_prompt(
    prompt="Проанализируй этот дизайн",
    log_prefix="analyze_design_",  # Префикс для файлов логов
    log_full=True  # Логировать и запрос, и ответ полностью
)
```

### Метрики использования

Рекомендуется отслеживать следующие метрики:
- Количество запросов к LLM
- Количество токенов в запросах и ответах
- Время ответа
- Частота ошибок
- Частота повторных запросов

### Примеры отладочных инструментов

```python
# Отладочный инструмент для просмотра рендеринга промпта без отправки в LLM
@mcp.tool()
async def debug_prompt_template(template_name: str, context: dict):
    """Отладка шаблона промпта без отправки в LLM"""
    rendered = prompt_manager.render_template(template_name, context)
    tokens = llm_adapter.estimate_tokens(rendered)
    return {
        "prompt": rendered,
        "estimated_tokens": tokens,
        "estimated_cost": f"${tokens * 0.00002:.6f}" if tokens > 0 else "N/A"
    }
```

## Заключение

AI-интеграция в MCP-сервере предоставляет мощные инструменты для автоматизации работы с дизайном в Figma. Правильное использование LLM с хорошо структурированными промптами и эффективное управление контекстом позволяют получать высококачественные результаты для различных задач дизайна и разработки.

Для дальнейшего развития рекомендуется:
1. Регулярно обновлять шаблоны промптов на основе обратной связи
2. Экспериментировать с различными форматами запросов для разных задач
3. Собирать и анализировать данные об использовании для оптимизации
4. Рассмотреть возможность тонкой настройки моделей на специфику дизайн-задач 